{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2841b365",
   "metadata": {},
   "source": [
    "# üîç Multimodal RAG System: Pipeline Demo (–±–µ–∑ UI)\n",
    "\n",
    "–ú–µ—Ç–∞ ‚Äî –ø–æ–±—É–¥—É–≤–∞—Ç–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—É RAG-—Å–∏—Å—Ç–µ–º—É –Ω–∞ –±–∞–∑—ñ —Å—Ç–∞—Ç–µ–π –∑ The Batch, —â–æ –≤–∫–ª—é—á–∞—î —ñ —Ç–µ–∫—Å—Ç, —ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05019de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "c:\\Programming\\anaconda\\envs\\rag_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∏\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # –¥–ª—è –ø–æ–¥—ñ–ª—É —Ç–µ–∫—Å—Ç—É –Ω–∞ —à–º–∞—Ç–∫–∏\n",
    "from langchain.embeddings import HuggingFaceEmbeddings # –¥–ª—è embeddings\n",
    "from langchain_chroma import Chroma # –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –±–¥\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f8abef",
   "metadata": {},
   "source": [
    "## 1. üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Å—Ç–∞—Ç–µ–π —Ç–∞ –∑–æ–±—Ä–∞–∂–µ–Ω—å\n",
    "\n",
    "- –í–∏—Ç—è–≥—É—î–º–æ —Ç–µ–∫—Å—Ç —ñ –∫–∞—Ä—Ç–∏–Ω–∫–∏ (—á–µ—Ä–µ–∑ web scraping, API –∞–±–æ –≤—Ä—É—á–Ω—É).\n",
    "- –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Å–∏—Ä—ñ –¥–∞–Ω—ñ —É `data/raw_articles/` —Ç–∞ `data/images/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f59b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.deeplearning.ai/the-batch/google-upgrades-its-ai-music-tools-for-professional-use/\"\n",
    "urls = [\"https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/\",\"https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/\",\"https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aacbd9",
   "metadata": {},
   "source": [
    "–¥–∞–ª—ñ —Ç—Ä–µ–±–∞ —è–∫–æ—Å—å –∑–ø–∞—Ä—Å–∏—Ç–∏ –≤—Å–µ —Ç–µ —Ç–æ–º—É –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—é beatifulsoup \n",
    "pip install beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c5f608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/ - –ó–Ω–∞–π–¥–µ–Ω–æ contents 1 –µ–ª–µ–º–µ–Ω—Çs\n",
      "https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/ - –ó–Ω–∞–π–¥–µ–Ω–æ imgs 1 –µ–ª–µ–º–µ–Ω—Çs\n",
      "https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/ - –ó–Ω–∞–π–¥–µ–Ω–æ contents 1 –µ–ª–µ–º–µ–Ω—Çs\n",
      "https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/ - –ó–Ω–∞–π–¥–µ–Ω–æ imgs 2 –µ–ª–µ–º–µ–Ω—Çs\n",
      "https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/ - –ó–Ω–∞–π–¥–µ–Ω–æ contents 1 –µ–ª–µ–º–µ–Ω—Çs\n",
      "https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/ - –ó–Ω–∞–π–¥–µ–Ω–æ imgs 3 –µ–ª–µ–º–µ–Ω—Çs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['/_next/image/?url=https%3A%2F%2Fcharonhub.deeplearning.ai%2Fcontent%2Fimages%2F2025%2F06%2Funnamed---2025-06-04T165349.311-1.png&w=3840&q=75'],\n",
       " ['/_next/image/?url=https%3A%2F%2Fcharonhub.deeplearning.ai%2Fcontent%2Fimages%2F2025%2F03%2Funnamed--65--1.png&w=3840&q=75'],\n",
       " ['/_next/image/?url=https%3A%2F%2Fcharonhub.deeplearning.ai%2Fcontent%2Fimages%2F2024%2F07%2Funnamed--70--1.jpg&w=3840&q=75']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents = []\n",
    "images = []\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    initial_images = [img.get('src') for img in soup.find_all('img') if img.get('src')]\n",
    "    images.append([url for url in initial_images if 'gif' not in url.lower() and 'wordpress' not in url.lower() and 'svg+xml' not in url.lower() and 'batch-logo' not in url.lower()])\n",
    "    elements = soup.select(\".prose--styled\") # –≤–∏–±–∏—Ä–∞—î—Å–º–æ –∫–ª–∞—Å–∏, –∑–∞–ø–∏—Å—É—î—Ç—å—Å—è –≤ –∑–≤–æ—Ä–æ—Ç–Ω—å–æ–º—É –ø–æ—Ä—è–¥–∫—É\n",
    "    print(f\"{url} - –ó–Ω–∞–π–¥–µ–Ω–æ contents {len(elements)} –µ–ª–µ–º–µ–Ω—Çs\")\n",
    "    print(f\"{url} - –ó–Ω–∞–π–¥–µ–Ω–æ imgs {len(images)} –µ–ª–µ–º–µ–Ω—Çs\")\n",
    "    contents.append(elements[0].get_text(separator=' ')) # –Ω–æ—Ä–º–∞–ª—å–Ω–∏–π —Ç–µ–∫—Å—Ç\n",
    "contents\n",
    "images    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "771e667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for content in contents:\n",
    "    loader = WebBaseLoader(web_paths=urls)\n",
    "    text_docs = loader.load()\n",
    "text_docs[0].page_content = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0273829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4922"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ (–º–æ–∂–Ω–∞ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–∏)\n",
    "(len(text_docs[2].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c665ed17",
   "metadata": {},
   "source": [
    "## 2. üßπ –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—ñ–Ω–≥ —Ç–µ–∫—Å—Ç—É —Ç–∞ –∑–æ–±—Ä–∞–∂–µ–Ω—å (—Ü–µ –≤–∑–∞–≥–∞–ª—ñ —Ç—Ä–µ–±–∞?)\n",
    "\n",
    "- –û—á–∏—â–∞—î–º–æ HTML, –≤–∏—Ç—è–≥—É—î–º–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏, –æ—Å–Ω–æ–≤–Ω–∏–π —Ç–µ–∫—Å—Ç.\n",
    "- –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ä–æ–∑—à–∏—Ä–µ–Ω—å, –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –Ω–∞–∑–≤, –∑–º–µ–Ω—à–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω—å.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbb916f",
   "metadata": {},
   "source": [
    "### —Ç–µ–∫—Å—Ç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057d37e2",
   "metadata": {},
   "source": [
    "–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ langchain –¥–ª—è –ø–æ–¥—ñ–ª—É —Ç–µ–∫—Å—Ç—É –Ω–∞ —à–º–∞—Ç–∫–∏ (pip install langchain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1daa9d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split post into 30 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "all_text_splits = []\n",
    "\n",
    "for text_doc in text_docs:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,  # chunk size (characters)\n",
    "    chunk_overlap=100,  # chunk overlap (characters) (–ø–µ—Ä–µ–∫—Ä–∏—Ç—Ç—è –º—ñ–∂ —Å—É–º—ñ–∂–Ω–∏–º–∏ —à–º–∞—Ç–∫–∞–º–∏ (50 —Å–∏–º–≤–æ–ª—ñ–≤ (–∞–±–æ —Å–ª—ñ–≤) –∑ –∫—ñ–Ω—Ü—è –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ–≥–æ —à–º–∞—Ç–∫–∞ –ø–æ–≤—Ç–æ—Ä—é—é—Ç—å—Å—è –Ω–∞ –ø–æ—á–∞—Ç–∫—É –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ)\n",
    "    add_start_index=True,  # track index in original document\n",
    "    )\n",
    "\n",
    "    all_text_splits += text_splitter.split_documents(text_docs)\n",
    "\n",
    "print(f\"Split post into {len(all_text_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd44d2b",
   "metadata": {},
   "source": [
    "pip install langchain-community (–±–æ –µ–º–±–µ–¥—ñ–Ω–≥–∏ –Ω–µ –ø—Ä–∞—Ü—é—é—Ç—å)\n",
    "pip install langchain-huggingface (–ø—Ä–æ–±–ª–µ–º–∏ –ø–∞–∫–µ—Ç—ñ–≤)\n",
    "pip install sentence-transformers (—Ü–µ –≤—Å–µ –¥–ª—è –ª–∞–Ω–≥—á–µ—ñ–Ω)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b5a80c",
   "metadata": {},
   "source": [
    "## 3. üß† –ï–º–±–µ–¥–¥–∏–Ω–≥ —Ç–µ–∫—Å—Ç—É\n",
    "\n",
    "- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ SentenceTransformers –∞–±–æ OpenAI –¥–ª—è —Ç–µ–∫—Å—Ç—É.\n",
    "- –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –µ–º–±–µ–¥–∏–Ω–≥–∏ + —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–∏ —Å—Ç–∞—Ç–µ–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea56552e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_29604\\1425009756.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n"
     ]
    }
   ],
   "source": [
    "#  –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –µ–º–±–µ–¥–∏–Ω–≥-–º–æ–¥–µ–ª—ñ\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e65abce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated vectors of length 768\n",
      "\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "vector_1 = embeddings.embed_query(all_text_splits[0].page_content)\n",
    "vector_2 = embeddings.embed_query(all_text_splits[1].page_content)\n",
    "\n",
    "assert len(vector_1) == len(vector_2)\n",
    "print(f\"Generated vectors of length {len(vector_1)}\\n\")\n",
    "print(type(vector_1[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f4c891",
   "metadata": {},
   "source": [
    "## 4. üñºÔ∏è –ï–º–±–µ–¥–¥–∏–Ω–≥ –∑–æ–±—Ä–∞–∂–µ–Ω—å\n",
    "\n",
    "- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ CLIP, BLIP –∞–±–æ ViT.\n",
    "- –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ñ—ñ—á—ñ –∑–æ–±—Ä–∞–∂–µ–Ω—å —ñ –ø—Ä–∏–≤‚Äô—è–∑—É—î–º–æ –¥–æ —Å—Ç–∞—Ç–µ–π."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063d277b",
   "metadata": {},
   "source": [
    "pip install torch torchvision transformers Pillow requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf77737f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/_next/image/?url=https%3A%2F%2Fcharonhub.deeplearning.ai%2Fcontent%2Fimages%2F2025%2F06%2Funnamed---2025-06-04T165349.311-1.png&w=3840&q=75\n"
     ]
    }
   ],
   "source": [
    "print(images[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad8947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "–†–æ–∑–º—ñ—Ä embedding: 512\n",
      "<class 'list'>\n",
      "–†–æ–∑–º—ñ—Ä embedding: 512\n",
      "<class 'list'>\n",
      "–†–æ–∑–º—ñ—Ä embedding: 512\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å —ñ –ø—Ä–æ—Ü–µ—Å–æ—Ä\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "model = CLIPModel.from_pretrained(model_name)\n",
    "processor = CLIPProcessor.from_pretrained(model_name, use_fast=True)\n",
    "img_embeddings = []\n",
    "img_metadata = []\n",
    "\n",
    "# –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ URL (–∞–±–æ –≤—ñ–¥–∫—Ä–∏–≤–∞—î–º–æ –ª–æ–∫–∞–ª—å–Ω–∏–π —Ñ–∞–π–ª)\n",
    "for url in images:\n",
    "    image = Image.open(requests.get('https://www.deeplearning.ai'+url[0], stream=True).raw).convert(\"RGB\")# –Ø–∫—â–æ –ª–æ–∫–∞–ª—å–Ω–∏–π —Ñ–∞–π–ª: image = Image.open(\"path/to/image.jpg\").convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")# –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è –º–æ–¥–µ–ª—ñ\n",
    "\n",
    "    # –û—Ç—Ä–∏–º—É—î–º–æ embedding\n",
    "    with torch.no_grad():\n",
    "        image_features = model.get_image_features(**inputs)\n",
    "\n",
    "    image_embedding = image_features / image_features.norm(p=2, dim=-1, keepdim=True) # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –≤–µ–∫—Ç–æ—Ä (–¥–æ–±—Ä–µ –¥–ª—è –ø–æ—à—É–∫—É –∑–∞ –∫–æ—Å–∏–Ω—É—Å–Ω–æ—é —Å—Ö–æ–∂—ñ—Å—Ç—é)\n",
    "\n",
    "\n",
    "    # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ —É numpy-–º–∞—Å–∏–≤ (–∑—Ä—É—á–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è)\n",
    "    # embedding_vector = image_embedding.cpu().numpy()[0]\n",
    "    print(type(image_features.squeeze().cpu().tolist()))\n",
    "    img_embeddings.append(image_features.squeeze().cpu().tolist())\n",
    "    img_metadata.append({\"url\": url[0], \"id\":None})\n",
    "    print(\"–†–æ–∑–º—ñ—Ä embedding:\", len())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e4d6766",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_docs = []\n",
    "for emb, meta in zip(img_embeddings, img_metadata):\n",
    "    # –°—Ç–≤–æ—Ä—é—î–º–æ Document –∑ –ø–æ—Ä–æ–∂–Ω—ñ–º —Ç–µ–∫—Å—Ç–æ–º, —â–æ–± –∑–±–µ—Ä–µ–≥—Ç–∏ embedding —Ç–∞ –º–µ—Ç–∞–¥–∞–Ω—ñ\n",
    "    img_docs.append(Document(page_content=\"\", metadata=meta))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69875dce",
   "metadata": {},
   "source": [
    "## 5. üóÉÔ∏è –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ —ñ–Ω–¥–µ–∫—Å—É\n",
    "\n",
    "- –û–±‚Äô—î–¥–Ω—É—î–º–æ —Ç–µ–∫—Å—Ç–æ–≤—ñ + –≤—ñ–∑—É–∞–ª—å–Ω—ñ –µ–º–±–µ–¥–∏–Ω–≥–∏.\n",
    "- –Ü–Ω–¥–µ–∫—Å—É–≤–∞–Ω–Ω—è –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é FAISS / Chroma / Milvus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982f85df",
   "metadata": {},
   "source": [
    "pip install chromadb (—è —Ö–∑ —á–∏ —Ü–µ —Ç—Ä–µ–±–∞)\n",
    "pip install langchain-chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72a9ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"chroma_langchain_db/\",  # Where to save data locally, remove if not necessary\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc432b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f38d6c4e-4b61-4758-aeb3-708c3a853492',\n",
       " '1657efb0-1bff-4f1f-b4b4-643c84027b83',\n",
       " '1d633b72-6835-4e4a-a7a1-644f250bc91b',\n",
       " 'e782133f-6ce8-413c-8673-0f9b20b245d9',\n",
       " '960af1bb-c956-408d-818e-dec0006f5ba8',\n",
       " 'fb22e543-8879-4418-8fe9-2a17e407f84f',\n",
       " '549eed4e-c153-4118-8c99-888ab41ce0c8',\n",
       " 'f2755d89-2bff-4a71-aaf3-e830b2b88fe5',\n",
       " '0e7d2f4f-42b8-4b35-829d-20bf61333fa6',\n",
       " 'e5d791c6-9bdf-4499-aaea-1890fbdcbc5f',\n",
       " '2e632670-a103-4552-8de9-b3e80f2a67c3',\n",
       " '87d3997f-0112-41ee-9613-aa580fc39a31',\n",
       " '16bdba5d-e2f8-415e-9320-1318e47d049a',\n",
       " '906082bc-09a8-4952-808b-75f99002dd70',\n",
       " 'ff556279-cb72-48d7-a095-afd634c8e637',\n",
       " '78205af8-fea1-4126-8fe3-e9177aae7267',\n",
       " 'f3556cd9-be36-44a0-82b9-d4a254d738d7',\n",
       " '9577d74f-0ca3-43f8-8564-d305ad1483a3',\n",
       " 'f5f9ef2a-f2ea-497f-a1b4-e25d316c1b9e',\n",
       " '9c1da78a-6989-4a11-b082-90c054c2070d',\n",
       " '28d47d7f-6b56-4af7-b2bd-6b806d94e964',\n",
       " 'e0dcec7a-5568-4656-8c8a-a10ffae54045',\n",
       " 'cb9aaec7-b883-4835-b5b1-f9473183ef8e',\n",
       " 'a0f3aaed-157f-4d22-89aa-8291055ea46c',\n",
       " '359673aa-8d89-46f2-bc0a-e2dff315375c',\n",
       " '83a69fb8-4d62-4c57-86a9-bb71cced7606',\n",
       " '907b1a20-560d-439d-b21b-174767924402',\n",
       " '81c89409-1a0b-4d77-a594-3a82b7b50c0b',\n",
       " 'ec86fff9-6d90-4cdd-baf8-9ed088a43210',\n",
       " 'a75af222-f67d-4ce8-8b6a-a8edac508216']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=all_text_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0209201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['66f5694e-4eba-4e3a-8f45-dc274afeb9a6',\n",
       " 'd0c13dab-7be0-4b3c-951e-6d2b6237b141',\n",
       " 'd199bad1-ce7d-46f5-abbf-dd0c5ae53794']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(img_docs, embeddings=img_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e65fe",
   "metadata": {},
   "source": [
    "## 6. ‚ùì–ó–∞–ø–∏—Ç —ñ –†–µ—Ç—Ä—ñ–≤–∞–ª\n",
    "\n",
    "- –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á —Ñ–æ—Ä–º—É–ª—é—î –∑–∞–ø–∏—Ç (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥: ‚Äú–©–æ –Ω–æ–≤–æ–≥–æ –≤ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞—Ö NVIDIA?‚Äù).\n",
    "- –ï–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø–∏—Ç—É.\n",
    "- –ü–æ—à—É–∫ —É –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–º—É —ñ–Ω–¥–µ–∫—Å—ñ.\n",
    "- –í–∏–≤—ñ–¥: —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—Ç—ñ + –ø–æ–≤‚Äô—è–∑–∞–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6308f6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='AI and Data Center Boom Challenges Big Tech's Emissions Targets‚ú® New course! Enroll in Building with Llama 4Explore CoursesAI NewsletterThe BatchAndrew's LetterData PointsML ResearchBlogCommunityForumEventsAmbassadorsAmbassador SpotlightResourcesCompanyAboutCareersContactStart LearningWeekly IssuesAndrew's LettersData PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe BatchTech & SocietyArticleAI‚Äôs Path to Zero Emissions Is Cloudy AI and data center boom challenges big tech's emissions targetsTech & SocietyScience#Import 2025-06-13 02:32PublishedJul 10, 2024Reading time3 min readShareThe boom in AI is jeopardizing big tech‚Äôs efforts to reach its targets for emissions of greenhouse gasses.What‚Äôs new:¬†Google‚Äôs¬†annual environmental report¬†shows that the company‚Äôs total carbon dioxide emissions rose nearly 50 percent between 2019 and 2023 to 14.3 million tons. Google attributes the rise to its efforts to satisfy rising demand for AI.¬†How it works:¬†Google‚Äôs carbon' metadata={'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\", 'description': 'The boom in AI is jeopardizing big tech‚Äôs efforts to reach its targets for emissions of greenhouse gasses...', 'start_index': 0, 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"How is AI growth impacting tech companies' carbon goals and data center emissions?\"\n",
    ")\n",
    "\n",
    "print((results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0992ea6c",
   "metadata": {},
   "source": [
    "## 7. ‚úÖ –ü—ñ–¥—Å—É–º–æ–∫ —ñ –æ—Ü—ñ–Ω–∫–∞\n",
    "\n",
    "- –Ø–∫—ñ—Å—Ç—å –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π\n",
    "- –ù–∞—Å–∫—ñ–ª—å–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
