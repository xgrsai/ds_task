{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2841b365",
   "metadata": {},
   "source": [
    "# Multimodal RAG: Pipeline Demo\n",
    "\n",
    "Мета - побудувати мультимодальну RAG-систему на базі статей з The Batch, що включає і текст, і зображення.\n",
    "### Щоб працював StremLit додаток необхідно запустити кроки 1-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05019de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## бібліотеки\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # для поділу тексту на шматки\n",
    "from PIL import Image\n",
    "from chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction\n",
    "import chromadb\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API\")\n",
    "\n",
    "# from huggingface_hub import InferenceClient # для (типу) хорошої відповіді\n",
    "# from transformers import BlipProcessor, BlipForConditionalGeneration # для опису зображень\n",
    "# from chromadb.utils.data_loaders import ImageLoader\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings # для embeddings - лише текстової"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f8abef",
   "metadata": {},
   "source": [
    "## 1. Завантаження статей та зображень\n",
    "Витягуємо текст і картинку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f59b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.deeplearning.ai/the-batch/google-upgrades-its-ai-music-tools-for-professional-use/\"\n",
    "urls = [\"https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/\",\"https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/\",\"https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aacbd9",
   "metadata": {},
   "source": [
    "далі треба якось спарсити все те"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c5f608",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []\n",
    "images = []\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    initial_images = [img.get('src') for img in soup.find_all('img') if img.get('src')]\n",
    "    images.append([url for url in initial_images if 'gif' not in url.lower() and 'wordpress' not in url.lower() and 'svg+xml' not in url.lower() and 'batch-logo' not in url.lower()])\n",
    "    elements = soup.select(\".prose--styled\") # вибираєсмо класи, записується в зворотньому порядку\n",
    "    print(f\"{url} - Знайдено contents {len(elements)} елементs\")\n",
    "    print(f\"{url} - Знайдено imgs {len(images)} елементs\")\n",
    "    contents.append(elements[0].get_text(separator=' ')) # нормальний текст\n",
    "contents\n",
    "images    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c665ed17",
   "metadata": {},
   "source": [
    "## 2. Препроцесінг тексту та зображень"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f23db1",
   "metadata": {},
   "source": [
    "витягнений текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for content in contents:\n",
    "    loader = WebBaseLoader(web_paths=urls)\n",
    "    text_docs = loader.load()\n",
    "text_docs[0].page_content = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0273829",
   "metadata": {},
   "outputs": [],
   "source": [
    "### перевірка (можна пропустити)\n",
    "(len(text_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f742e011",
   "metadata": {},
   "source": [
    "збереження зображення"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a28832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"https://www.deeplearning.ai\"\n",
    "img_dir = \"downloaded_images\"\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "\n",
    "count = 0\n",
    "for image_urls in images:\n",
    "    for img_url in image_urls:\n",
    "        resp = requests.get(prefix+img_url)\n",
    "        ext_part = img_url.split('.')[-1] # Відокремлюємо частину після останньої крапки, а потім беремо до ? або &\n",
    "        ext = ext_part.split('?')[0].split('&')[0]  # Обрізаємо параметри\n",
    "        filename = f\"img_{count}.{ext}\"\n",
    "        filepath = os.path.join(img_dir, filename)\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            f.write(resp.content)\n",
    "        # print(resp)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4789d5ea",
   "metadata": {},
   "source": [
    "перетворення зображень на numpy масив"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f65686",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"downloaded_images\"\n",
    "numpy_images = []\n",
    "\n",
    "for filename in os.listdir(img_dir):\n",
    "    filepath = os.path.join(img_dir, filename)\n",
    "    with Image.open(filepath) as img:\n",
    "        img = img.convert(\"RGB\") \n",
    "        np_img = np.array(img)\n",
    "        numpy_images.append(np_img)\n",
    "\n",
    "print(f\"Завантажено та конвертовано {len(numpy_images)} images у numpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbb916f",
   "metadata": {},
   "source": [
    "### поділ тексту"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057d37e2",
   "metadata": {},
   "source": [
    "використовуємо langchain для поділу тексту на шматки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daa9d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_splits = []\n",
    "\n",
    "for text_doc in text_docs:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=100,  # chunk overlap (characters) (перекриття між суміжними шматками (50 символів (або слів) з кінця попереднього шматка повторюються на початку наступного)\n",
    "    add_start_index=True,  # track index in original document\n",
    "    )\n",
    "\n",
    "    all_text_splits += text_splitter.split_documents(text_docs)\n",
    "\n",
    "print(f\"Split post into {len(all_text_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d31a1",
   "metadata": {},
   "source": [
    "## 3-4 мультимодальний ембединг\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9c270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = OpenCLIPEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69875dce",
   "metadata": {},
   "source": [
    "## 5. Створення мультимодального індексу"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a74ab0",
   "metadata": {},
   "source": [
    "### метадані та ід"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d486bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### id\n",
    "text_ids = [f\"text_{i}\" for i in range(len(all_text_splits))] # ід для тексту\n",
    "image_ids = [f\"img_{i}\" for i in range(len(numpy_images))] # ід для зображень\n",
    "# img_description_ids = [f\"img_desc_{i}\" for i in range(len(numpy_images))] # id опису зображень\n",
    "\n",
    "text_documents = [doc.page_content for doc in all_text_splits] # для хрома (бо док-лангчеін не їсть)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9776e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_metadatas = []\n",
    "for split in all_text_splits:\n",
    "    text_metadatas.append({\n",
    "        \"type\": \"text\",\n",
    "        \"source\": split.metadata.get(\"source\", \"unknown\"),  # якщо є\n",
    "        \"title\": split.metadata.get(\"title\", \"no_title\"),\n",
    "    })\n",
    "\n",
    "image_metadatas = []\n",
    "for text_doc in text_docs:\n",
    "    image_metadatas.append({\n",
    "        \"type\": \"image\",\n",
    "        \"source\": text_doc.metadata.get(\"source\", \"unknown\"),  # якщо є\n",
    "        \"title\": text_doc.metadata.get(\"title\", \"no_title\"),\n",
    "        \"local_path\": img_dir + ''\n",
    "        \n",
    "    })    \n",
    "\n",
    "# img_desc_metadatas = [] - на перспективу\n",
    "# for text_doc,id_img in zip(text_docs,image_ids):\n",
    "#     img_desc_metadatas.append({\n",
    "#         \"type\": \"text\",\n",
    "#         \"source\": text_doc.metadata.get(\"source\", \"unknown\"),  # якщо є\n",
    "#         \"title\": text_doc.metadata.get(\"title\", \"no_title\"),\n",
    "#         \"image_ids\": id_img,\n",
    "#     })        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b32bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#перевірка (optional)\n",
    "print(text_metadatas)\n",
    "print(image_metadatas)\n",
    "# print(img_desc_metadatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaca4dd",
   "metadata": {},
   "source": [
    "### також додамо опис для зображень (SKIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81063be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "# model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "# def generate_caption(image):\n",
    "#     inputs = processor(image, return_tensors=\"pt\")\n",
    "#     out = model.generate(**inputs)\n",
    "#     caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "#     return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c895a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_description = []\n",
    "# for img in numpy_images:\n",
    "#     img_pil = Image.fromarray(img)\n",
    "#     caption = generate_caption(img_pil)\n",
    "#     image_description.append(caption)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67482755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(image_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d94013",
   "metadata": {},
   "source": [
    "### add до бд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f13228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader = ImageLoader() # для зберігання з uris \n",
    "client = chromadb.PersistentClient(path=\"chroma_langchain_db/\") # для збереження локально\n",
    "\n",
    "collection = client.create_collection(\n",
    "    name='multimodal_collection',\n",
    "    embedding_function=embedding_function,\n",
    "    # data_loader=data_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54732609",
   "metadata": {},
   "outputs": [],
   "source": [
    "###додаєм до век бд текст\n",
    "collection.add(\n",
    "    ids=text_ids, \n",
    "    documents=text_documents,\n",
    "    metadatas=text_metadatas,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86228f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###додаєм до век бд зображення\n",
    "collection.add(\n",
    "    ids=image_ids,\n",
    "    images=numpy_images,\n",
    "    metadatas=image_metadatas,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0179a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP\n",
    "# ###додаєм до век бд описи зображення\n",
    "# collection.add(\n",
    "#     ids=img_description_ids,\n",
    "#     documents=image_description,\n",
    "#     metadatas=image_metadatas,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# перевірка (optional)\n",
    "print(collection.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e65fe",
   "metadata": {},
   "source": [
    "## 6. Запит і Ретрівал (тести) (optional)\n",
    "\n",
    "- Користувач формулює запит (наприклад: “Що нового в архітектурах NVIDIA?”).\n",
    "- Вивід: текст статті + пов’язане зображення."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d44b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#тест на зображенні\n",
    "results = collection.query(\n",
    "    query_images=[numpy_images[0]]\n",
    ")\n",
    "\n",
    "print((results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7c8606",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = results.get('documents', [[]])[0]  # перший список документів\n",
    "\n",
    "first_non_none_doc = next((doc for doc in docs if doc is not None), None)\n",
    "print(first_non_none_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6308f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#тест на тексті\n",
    "results = collection.query(\n",
    "    query_texts=[\"How is AI growth impacting tech companies' carbon goals and data center emissions?\"]\n",
    ")\n",
    "\n",
    "print((results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['metadatas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d62ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_metadata = results['metadatas'][0][0]\n",
    "first_source = first_metadata.get('source')\n",
    "first_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedeab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_imgs = collection.get(\n",
    "    where={\n",
    "        \"$and\": [\n",
    "            {\"source\": first_source},\n",
    "            {\"type\": \"image\"}\n",
    "        ]\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e8030",
   "metadata": {},
   "source": [
    "вивести зображення"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3c596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_file_by_prefix(prefix, folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.startswith(prefix):\n",
    "            return os.path.join(folder, filename)\n",
    "    return None\n",
    "\n",
    "for img_id in results_imgs['ids']:\n",
    "    filepath = find_file_by_prefix(img_id, img_dir)\n",
    "    if filepath and os.path.exists(filepath):\n",
    "        img = Image.open(filepath)\n",
    "        img.show()\n",
    "    else:\n",
    "        print(f\"Файл для {img_id} не знайдено\")\n",
    "filepath        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc5745",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc0a479",
   "metadata": {},
   "source": [
    "лише текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6010b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "with open(filepath, 'rb') as f:\n",
    "      image_bytes = f.read()\n",
    "query = \"How is AI growth impacting tech companies' carbon goals and data center emissions?\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    contents=[\n",
    "        types.Part(text=(\n",
    "            \"You are given a piece of text and an image. \"\n",
    "            \"Based on both, provide a clear, structured, and factual response to the following query.\\n\\n\"\n",
    "            \"Context:\\n\"\n",
    "            f\"{results['documents'][0][0]}\\n\\n\"\n",
    "            \"Query:\\n\"\n",
    "            f\"{query}\\n\"\n",
    "            \"Use only the information available in the context and image. If you cannot answer based on that, say so honestly.\"\n",
    "        )),\n",
    "        types.Part.from_bytes(\n",
    "            data=image_bytes,\n",
    "            mime_type='image/jpeg',\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
