{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2841b365",
   "metadata": {},
   "source": [
    "# ðŸ” Multimodal RAG System: Pipeline Demo (Ð±ÐµÐ· UI)\n",
    "\n",
    "ÐœÐµÑ‚Ð° â€” Ð¿Ð¾Ð±ÑƒÐ´ÑƒÐ²Ð°Ñ‚Ð¸ Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ð¼Ð¾Ð´Ð°Ð»ÑŒÐ½Ñƒ RAG-ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ Ð½Ð° Ð±Ð°Ð·Ñ– ÑÑ‚Ð°Ñ‚ÐµÐ¹ Ð· The Batch, Ñ‰Ð¾ Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ” Ñ– Ñ‚ÐµÐºÑÑ‚, Ñ– Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05019de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "## Ð±Ñ–Ð±Ð»Ñ–Ð¾Ñ‚ÐµÐºÐ¸\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # Ð´Ð»Ñ Ð¿Ð¾Ð´Ñ–Ð»Ñƒ Ñ‚ÐµÐºÑÑ‚Ñƒ Ð½Ð° ÑˆÐ¼Ð°Ñ‚ÐºÐ¸\n",
    "from PIL import Image\n",
    "from chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction\n",
    "import chromadb\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API\")\n",
    "\n",
    "# from huggingface_hub import InferenceClient # Ð´Ð»Ñ (Ñ‚Ð¸Ð¿Ñƒ) Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾Ñ— Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ–\n",
    "# from transformers import BlipProcessor, BlipForConditionalGeneration # Ð´Ð»Ñ Ð¾Ð¿Ð¸ÑÑƒ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ\n",
    "# from chromadb.utils.data_loaders import ImageLoader\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings # Ð´Ð»Ñ embeddings - Ð»Ð¸ÑˆÐµ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ñ—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f8abef",
   "metadata": {},
   "source": [
    "## 1. Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ ÑÑ‚Ð°Ñ‚ÐµÐ¹ Ñ‚Ð° Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ\n",
    "Ð’Ð¸Ñ‚ÑÐ³ÑƒÑ”Ð¼Ð¾ Ñ‚ÐµÐºÑÑ‚ Ñ– ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÑƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f59b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.deeplearning.ai/the-batch/google-upgrades-its-ai-music-tools-for-professional-use/\"\n",
    "urls = [\"https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/\",\"https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/\",\"https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aacbd9",
   "metadata": {},
   "source": [
    "Ð´Ð°Ð»Ñ– Ñ‚Ñ€ÐµÐ±Ð° ÑÐºÐ¾ÑÑŒ ÑÐ¿Ð°Ñ€ÑÐ¸Ñ‚Ð¸ Ð²ÑÐµ Ñ‚Ðµ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c5f608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/ - Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ contents 1 ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚s\n",
      "https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/ - Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ imgs 1 ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚s\n",
      "https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/ - Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ contents 1 ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚s\n",
      "https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/ - Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ imgs 2 ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚s\n",
      "https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/ - Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ contents 1 ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚s\n",
      "https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/ - Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ imgs 3 ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['/_next/image/?url=https%3A%2F%2Fcharonhub.deeplearning.ai%2Fcontent%2Fimages%2F2025%2F06%2Funnamed---2025-06-04T165349.311-1.png&w=3840&q=75'],\n",
       " ['/_next/image/?url=https%3A%2F%2Fcharonhub.deeplearning.ai%2Fcontent%2Fimages%2F2025%2F03%2Funnamed--65--1.png&w=3840&q=75'],\n",
       " ['/_next/image/?url=https%3A%2F%2Fcharonhub.deeplearning.ai%2Fcontent%2Fimages%2F2024%2F07%2Funnamed--70--1.jpg&w=3840&q=75']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents = []\n",
    "images = []\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    initial_images = [img.get('src') for img in soup.find_all('img') if img.get('src')]\n",
    "    images.append([url for url in initial_images if 'gif' not in url.lower() and 'wordpress' not in url.lower() and 'svg+xml' not in url.lower() and 'batch-logo' not in url.lower()])\n",
    "    elements = soup.select(\".prose--styled\") # Ð²Ð¸Ð±Ð¸Ñ€Ð°Ñ”ÑÐ¼Ð¾ ÐºÐ»Ð°ÑÐ¸, Ð·Ð°Ð¿Ð¸ÑÑƒÑ”Ñ‚ÑŒÑÑ Ð² Ð·Ð²Ð¾Ñ€Ð¾Ñ‚Ð½ÑŒÐ¾Ð¼Ñƒ Ð¿Ð¾Ñ€ÑÐ´ÐºÑƒ\n",
    "    print(f\"{url} - Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ contents {len(elements)} ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚s\")\n",
    "    print(f\"{url} - Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ imgs {len(images)} ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚s\")\n",
    "    contents.append(elements[0].get_text(separator=' ')) # Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ñ‚ÐµÐºÑÑ‚\n",
    "contents\n",
    "images    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c665ed17",
   "metadata": {},
   "source": [
    "## 2. ÐŸÑ€ÐµÐ¿Ñ€Ð¾Ñ†ÐµÑÑ–Ð½Ð³ Ñ‚ÐµÐºÑÑ‚Ñƒ Ñ‚Ð° Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f23db1",
   "metadata": {},
   "source": [
    "Ð²Ð¸Ñ‚ÑÐ³Ð½ÐµÐ½Ð¸Ð¹ Ñ‚ÐµÐºÑÑ‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "771e667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for content in contents:\n",
    "    loader = WebBaseLoader(web_paths=urls)\n",
    "    text_docs = loader.load()\n",
    "text_docs[0].page_content = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0273829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° (Ð¼Ð¾Ð¶Ð½Ð° Ð¿Ñ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸)\n",
    "(len(text_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f742e011",
   "metadata": {},
   "source": [
    "Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð½Ñ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a28832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"https://www.deeplearning.ai\"\n",
    "img_dir = \"downloaded_images\"\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "\n",
    "count = 0\n",
    "for image_urls in images:\n",
    "    for img_url in image_urls:\n",
    "        resp = requests.get(prefix+img_url)\n",
    "        ext_part = img_url.split('.')[-1] # Ð’Ñ–Ð´Ð¾ÐºÑ€ÐµÐ¼Ð»ÑŽÑ”Ð¼Ð¾ Ñ‡Ð°ÑÑ‚Ð¸Ð½Ñƒ Ð¿Ñ–ÑÐ»Ñ Ð¾ÑÑ‚Ð°Ð½Ð½ÑŒÐ¾Ñ— ÐºÑ€Ð°Ð¿ÐºÐ¸, Ð° Ð¿Ð¾Ñ‚Ñ–Ð¼ Ð±ÐµÑ€ÐµÐ¼Ð¾ Ð´Ð¾ ? Ð°Ð±Ð¾ &\n",
    "        ext = ext_part.split('?')[0].split('&')[0]  # ÐžÐ±Ñ€Ñ–Ð·Ð°Ñ”Ð¼Ð¾ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸\n",
    "        filename = f\"img_{count}.{ext}\"\n",
    "        filepath = os.path.join(img_dir, filename)\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            f.write(resp.content)\n",
    "        # print(resp)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4789d5ea",
   "metadata": {},
   "source": [
    "Ð¿ÐµÑ€ÐµÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ Ð½Ð° numpy Ð¼Ð°ÑÐ¸Ð²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00f65686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð¾ Ñ‚Ð° ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¾Ð²Ð°Ð½Ð¾ 3 images Ñƒ numpy\n"
     ]
    }
   ],
   "source": [
    "img_dir = \"downloaded_images\"\n",
    "numpy_images = []\n",
    "\n",
    "for filename in os.listdir(img_dir):\n",
    "    filepath = os.path.join(img_dir, filename)\n",
    "    with Image.open(filepath) as img:\n",
    "        img = img.convert(\"RGB\") \n",
    "        np_img = np.array(img)\n",
    "        numpy_images.append(np_img)\n",
    "\n",
    "print(f\"Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð¾ Ñ‚Ð° ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¾Ð²Ð°Ð½Ð¾ {len(numpy_images)} images Ñƒ numpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbb916f",
   "metadata": {},
   "source": [
    "### Ð¿Ð¾Ð´Ñ–Ð» Ñ‚ÐµÐºÑÑ‚Ñƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057d37e2",
   "metadata": {},
   "source": [
    "Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ð¼Ð¾ langchain Ð´Ð»Ñ Ð¿Ð¾Ð´Ñ–Ð»Ñƒ Ñ‚ÐµÐºÑÑ‚Ñƒ Ð½Ð° ÑˆÐ¼Ð°Ñ‚ÐºÐ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1daa9d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split post into 54 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "all_text_splits = []\n",
    "\n",
    "for text_doc in text_docs:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=100,  # chunk overlap (characters) (Ð¿ÐµÑ€ÐµÐºÑ€Ð¸Ñ‚Ñ‚Ñ Ð¼Ñ–Ð¶ ÑÑƒÐ¼Ñ–Ð¶Ð½Ð¸Ð¼Ð¸ ÑˆÐ¼Ð°Ñ‚ÐºÐ°Ð¼Ð¸ (50 ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ–Ð² (Ð°Ð±Ð¾ ÑÐ»Ñ–Ð²) Ð· ÐºÑ–Ð½Ñ†Ñ Ð¿Ð¾Ð¿ÐµÑ€ÐµÐ´Ð½ÑŒÐ¾Ð³Ð¾ ÑˆÐ¼Ð°Ñ‚ÐºÐ° Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑŽÑŽÑ‚ÑŒÑÑ Ð½Ð° Ð¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ Ð½Ð°ÑÑ‚ÑƒÐ¿Ð½Ð¾Ð³Ð¾)\n",
    "    add_start_index=True,  # track index in original document\n",
    "    )\n",
    "\n",
    "    all_text_splits += text_splitter.split_documents(text_docs)\n",
    "\n",
    "print(f\"Split post into {len(all_text_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d31a1",
   "metadata": {},
   "source": [
    "## 3-4 Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ð¼Ð¾Ð´Ð°Ð»ÑŒÐ½Ð¸Ð¹ ÐµÐ¼Ð±ÐµÐ´Ð¸Ð½Ð³\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef9c270d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programming\\anaconda\\envs\\rag_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding_function = OpenCLIPEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69875dce",
   "metadata": {},
   "source": [
    "## 5. ðŸ—ƒï¸ Ð¡Ñ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð¼ÑƒÐ»ÑŒÑ‚Ð¸Ð¼Ð¾Ð´Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ–Ð½Ð´ÐµÐºÑÑƒ\n",
    "\n",
    "- ÐžÐ±â€™Ñ”Ð´Ð½ÑƒÑ”Ð¼Ð¾ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ– + Ð²Ñ–Ð·ÑƒÐ°Ð»ÑŒÐ½Ñ– ÐµÐ¼Ð±ÐµÐ´Ð¸Ð½Ð³Ð¸.\n",
    "- Ð†Ð½Ð´ÐµÐºÑÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð° Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð¾ÑŽ FAISS / Chroma / Milvus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982f85df",
   "metadata": {},
   "source": [
    "pip install chromadb (Ñ Ñ…Ð· Ñ‡Ð¸ Ñ†Ðµ Ñ‚Ñ€ÐµÐ±Ð°)\n",
    "pip install langchain-chroma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a74ab0",
   "metadata": {},
   "source": [
    "### Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ñ– Ñ‚Ð° Ñ–Ð´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d486bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### id\n",
    "text_ids = [f\"text_{i}\" for i in range(len(all_text_splits))] # Ñ–Ð´ Ð´Ð»Ñ Ñ‚ÐµÐºÑÑ‚Ñƒ\n",
    "image_ids = [f\"img_{i}\" for i in range(len(numpy_images))] # Ñ–Ð´ Ð´Ð»Ñ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ\n",
    "# img_description_ids = [f\"img_desc_{i}\" for i in range(len(numpy_images))] # id Ð¾Ð¿Ð¸ÑÑƒ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ\n",
    "\n",
    "text_documents = [doc.page_content for doc in all_text_splits] # Ð´Ð»Ñ Ñ…Ñ€Ð¾Ð¼Ð° (Ð±Ð¾ Ð´Ð¾Ðº-Ð»Ð°Ð½Ð³Ñ‡ÐµÑ–Ð½ Ð½Ðµ Ñ—ÑÑ‚ÑŒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9776e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_metadatas = []\n",
    "for split in all_text_splits:\n",
    "    text_metadatas.append({\n",
    "        \"type\": \"text\",\n",
    "        \"source\": split.metadata.get(\"source\", \"unknown\"),  # ÑÐºÑ‰Ð¾ Ñ”\n",
    "        \"title\": split.metadata.get(\"title\", \"no_title\"),\n",
    "    })\n",
    "\n",
    "image_metadatas = []\n",
    "for text_doc in text_docs:\n",
    "    image_metadatas.append({\n",
    "        \"type\": \"image\",\n",
    "        \"source\": text_doc.metadata.get(\"source\", \"unknown\"),  # ÑÐºÑ‰Ð¾ Ñ”\n",
    "        \"title\": text_doc.metadata.get(\"title\", \"no_title\"),\n",
    "        \"local_path\": img_dir + ''\n",
    "        \n",
    "    })    \n",
    "\n",
    "# img_desc_metadatas = [] - Ð½Ð° Ð¿ÐµÑ€ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ñƒ\n",
    "# for text_doc,id_img in zip(text_docs,image_ids):\n",
    "#     img_desc_metadatas.append({\n",
    "#         \"type\": \"text\",\n",
    "#         \"source\": text_doc.metadata.get(\"source\", \"unknown\"),  # ÑÐºÑ‰Ð¾ Ñ”\n",
    "#         \"title\": text_doc.metadata.get(\"title\", \"no_title\"),\n",
    "#         \"image_ids\": id_img,\n",
    "#     })        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "205b32bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}]\n",
      "[{'type': 'image', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom'}, {'type': 'image', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'image', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}]\n"
     ]
    }
   ],
   "source": [
    "#Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° (optional)\n",
    "print(text_metadatas)\n",
    "print(image_metadatas)\n",
    "# print(img_desc_metadatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaca4dd",
   "metadata": {},
   "source": [
    "### Ñ‚Ð°ÐºÐ¾Ð¶ Ð´Ð¾Ð´Ð°Ð¼Ð¾ Ð¾Ð¿Ð¸Ñ Ð´Ð»Ñ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ (SKIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81063be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "# model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "# def generate_caption(image):\n",
    "#     inputs = processor(image, return_tensors=\"pt\")\n",
    "#     out = model.generate(**inputs)\n",
    "#     caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "#     return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c895a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_description = []\n",
    "# for img in numpy_images:\n",
    "#     img_pil = Image.fromarray(img)\n",
    "#     caption = generate_caption(img_pil)\n",
    "#     image_description.append(caption)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67482755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(image_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d94013",
   "metadata": {},
   "source": [
    "### add Ð´Ð¾ Ð±Ð´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f13228e",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Collection [multimodal_collection] already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# data_loader = ImageLoader() # Ð´Ð»Ñ Ð·Ð±ÐµÑ€Ñ–Ð³Ð°Ð½Ð½Ñ Ð· uris \u001b[39;00m\n\u001b[32m      2\u001b[39m client = chromadb.PersistentClient(path=\u001b[33m\"\u001b[39m\u001b[33mchroma_langchain_db/\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# Ð´Ð»Ñ Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð½Ñ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m collection = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmultimodal_collection\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# data_loader=data_loader,\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\anaconda\\envs\\rag_env\\Lib\\site-packages\\chromadb\\api\\client.py:168\u001b[39m, in \u001b[36mClient.create_collection\u001b[39m\u001b[34m(self, name, configuration, metadata, embedding_function, data_loader, get_or_create)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m configuration_ef \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    166\u001b[39m     configuration[\u001b[33m\"\u001b[39m\u001b[33membedding_function\u001b[39m\u001b[33m\"\u001b[39m] = embedding_function\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Collection(\n\u001b[32m    177\u001b[39m     client=\u001b[38;5;28mself\u001b[39m._server,\n\u001b[32m    178\u001b[39m     model=model,\n\u001b[32m    179\u001b[39m     embedding_function=embedding_function,\n\u001b[32m    180\u001b[39m     data_loader=data_loader,\n\u001b[32m    181\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programming\\anaconda\\envs\\rag_env\\Lib\\site-packages\\chromadb\\api\\rust.py:227\u001b[39m, in \u001b[36mRustBindingsAPI.create_collection\u001b[39m\u001b[34m(self, name, configuration, metadata, get_or_create, tenant, database)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    225\u001b[39m     configuration_json_str = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m collection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbindings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfiguration_json_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m collection_model = CollectionModel(\n\u001b[32m    231\u001b[39m     \u001b[38;5;28mid\u001b[39m=collection.id,\n\u001b[32m    232\u001b[39m     name=collection.name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m     database=collection.database,\n\u001b[32m    238\u001b[39m )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m collection_model\n",
      "\u001b[31mInternalError\u001b[39m: Collection [multimodal_collection] already exists"
     ]
    }
   ],
   "source": [
    "# data_loader = ImageLoader() # Ð´Ð»Ñ Ð·Ð±ÐµÑ€Ñ–Ð³Ð°Ð½Ð½Ñ Ð· uris \n",
    "client = chromadb.PersistentClient(path=\"chroma_langchain_db/\") # Ð´Ð»Ñ Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð½Ñ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾\n",
    "\n",
    "collection = client.create_collection(\n",
    "    name='multimodal_collection',\n",
    "    embedding_function=embedding_function,\n",
    "    # data_loader=data_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54732609",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Ð´Ð¾Ð´Ð°Ñ”Ð¼ Ð´Ð¾ Ð²ÐµÐº Ð±Ð´ Ñ‚ÐµÐºÑÑ‚\n",
    "collection.add(\n",
    "    ids=text_ids, \n",
    "    documents=text_documents,\n",
    "    metadatas=text_metadatas,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b86228f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Ð´Ð¾Ð´Ð°Ñ”Ð¼ Ð´Ð¾ Ð²ÐµÐº Ð±Ð´ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ\n",
    "collection.add(\n",
    "    ids=image_ids,\n",
    "    images=numpy_images,\n",
    "    metadatas=image_metadatas,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0179a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP\n",
    "# ###Ð´Ð¾Ð´Ð°Ñ”Ð¼ Ð´Ð¾ Ð²ÐµÐº Ð±Ð´ Ð¾Ð¿Ð¸ÑÐ¸ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ\n",
    "# collection.add(\n",
    "#     ids=img_description_ids,\n",
    "#     documents=image_description,\n",
    "#     metadatas=image_metadatas,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8957bca8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° (optional)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcollection\u001b[49m.count())\n",
      "\u001b[31mNameError\u001b[39m: name 'collection' is not defined"
     ]
    }
   ],
   "source": [
    "# Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° (optional)\n",
    "print(collection.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e65fe",
   "metadata": {},
   "source": [
    "## 6. Ð—Ð°Ð¿Ð¸Ñ‚ Ñ– Ð ÐµÑ‚Ñ€Ñ–Ð²Ð°Ð» (Ñ‚ÐµÑÑ‚Ð¸) (can be skipped)\n",
    "\n",
    "- ÐšÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡ Ñ„Ð¾Ñ€Ð¼ÑƒÐ»ÑŽÑ” Ð·Ð°Ð¿Ð¸Ñ‚ (Ð½Ð°Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´: â€œÐ©Ð¾ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð² Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð°Ñ… NVIDIA?â€).\n",
    "- Ð’Ð¸Ð²Ñ–Ð´: Ñ‚ÐµÐºÑÑ‚ ÑÑ‚Ð°Ñ‚Ñ‚Ñ– + Ð¿Ð¾Ð²â€™ÑÐ·Ð°Ð½Ðµ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f22d44b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['img_0', 'img_1', 'img_2', 'text_14', 'text_32', 'text_50', 'text_9', 'text_27', 'text_45', 'text_4']], 'embeddings': None, 'documents': [[None, None, None, 'have increased more than four-fold since 2019.Low-emissions energy has reduced Googleâ€™s total data-center emissions substantially, but some regions donâ€™t have enough of it to meet demand. Solar, wind, hydro, geothermal, and nuclear energy account for most of the energy consumed by Googleâ€™s data centers in Europe, Canada, and South America. However, these sources account for less than 5 percent in Singapore, Qatar, and Saudi Arabia.Countering the trend:\\xa0Google is working to reduce its greenhouse gas emissions on several fronts. Its effort to purchase electricity from low-emissions sources cut its net carbon footprint by around 30 percent in 2023. It claims that its owned-and-operated data centers are 1.8 times more energy-efficient than a typical enterprise data center, and its sixth-generation tensor processing units (TPUs) are 67 percent more efficient than the prior generation. Google has asked its largest hardware partners to match 100 percent of their energy consumption with', 'have increased more than four-fold since 2019.Low-emissions energy has reduced Googleâ€™s total data-center emissions substantially, but some regions donâ€™t have enough of it to meet demand. Solar, wind, hydro, geothermal, and nuclear energy account for most of the energy consumed by Googleâ€™s data centers in Europe, Canada, and South America. However, these sources account for less than 5 percent in Singapore, Qatar, and Saudi Arabia.Countering the trend:\\xa0Google is working to reduce its greenhouse gas emissions on several fronts. Its effort to purchase electricity from low-emissions sources cut its net carbon footprint by around 30 percent in 2023. It claims that its owned-and-operated data centers are 1.8 times more energy-efficient than a typical enterprise data center, and its sixth-generation tensor processing units (TPUs) are 67 percent more efficient than the prior generation. Google has asked its largest hardware partners to match 100 percent of their energy consumption with', 'have increased more than four-fold since 2019.Low-emissions energy has reduced Googleâ€™s total data-center emissions substantially, but some regions donâ€™t have enough of it to meet demand. Solar, wind, hydro, geothermal, and nuclear energy account for most of the energy consumed by Googleâ€™s data centers in Europe, Canada, and South America. However, these sources account for less than 5 percent in Singapore, Qatar, and Saudi Arabia.Countering the trend:\\xa0Google is working to reduce its greenhouse gas emissions on several fronts. Its effort to purchase electricity from low-emissions sources cut its net carbon footprint by around 30 percent in 2023. It claims that its owned-and-operated data centers are 1.8 times more energy-efficient than a typical enterprise data center, and its sixth-generation tensor processing units (TPUs) are 67 percent more efficient than the prior generation. Google has asked its largest hardware partners to match 100 percent of their energy consumption with', 'meta-review agent identifies common patterns in the reflection agentâ€™s reviews and the ranking agentâ€™s debates. Its feedback goes to the reflection and generation agents, which use it to address common factors in future reviews and avoid generating similar proposals, respectively.Results:\\xa0AI co-scientist achieved a number of impressive biomedical results in tests.Google researchers generated proposals for experiments that would repurpose drugs to treat acute myeloid leukemia. They shared the 30 highest-ranked proposals with human experts, who chose five for lab tests. Of the five drugs tested, three killed acute myeloid leukemia cells.Experts selected three among 15 top-ranked generated proposals that proposed repurposing existing drugs to treat liver fibrosis. Two significantly inhibited liver fibrosis without being toxic to general cells. (Prior to this research, one of the drugs was approved by the United States Food and Drug Administration for a different illness, which may lead', 'meta-review agent identifies common patterns in the reflection agentâ€™s reviews and the ranking agentâ€™s debates. Its feedback goes to the reflection and generation agents, which use it to address common factors in future reviews and avoid generating similar proposals, respectively.Results:\\xa0AI co-scientist achieved a number of impressive biomedical results in tests.Google researchers generated proposals for experiments that would repurpose drugs to treat acute myeloid leukemia. They shared the 30 highest-ranked proposals with human experts, who chose five for lab tests. Of the five drugs tested, three killed acute myeloid leukemia cells.Experts selected three among 15 top-ranked generated proposals that proposed repurposing existing drugs to treat liver fibrosis. Two significantly inhibited liver fibrosis without being toxic to general cells. (Prior to this research, one of the drugs was approved by the United States Food and Drug Administration for a different illness, which may lead', 'meta-review agent identifies common patterns in the reflection agentâ€™s reviews and the ranking agentâ€™s debates. Its feedback goes to the reflection and generation agents, which use it to address common factors in future reviews and avoid generating similar proposals, respectively.Results:\\xa0AI co-scientist achieved a number of impressive biomedical results in tests.Google researchers generated proposals for experiments that would repurpose drugs to treat acute myeloid leukemia. They shared the 30 highest-ranked proposals with human experts, who chose five for lab tests. Of the five drugs tested, three killed acute myeloid leukemia cells.Experts selected three among 15 top-ranked generated proposals that proposed repurposing existing drugs to treat liver fibrosis. Two significantly inhibited liver fibrosis without being toxic to general cells. (Prior to this research, one of the drugs was approved by the United States Food and Drug Administration for a different illness, which may lead', 'relieved to note that, for now, data centers and cloud computing are responsible for\\xa0 1 percent \\xa0of the worldâ€™s energy-related greenhouse gas emissions; a drop in the bucket compared to transportation, construction, or agriculture. Moreover, we believe that AI stands to create huge benefits relative to the climate impact of its emissions, and AI is one of the most powerful tools we have to develop low-carbon energy sources and boost energy efficiency throughout society. Continuing to improve the technology will help us develop lower-carbon energy sources and efficient ways to harness them.']], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[{'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'type': 'image'}, {'type': 'image', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/'}, {'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\", 'type': 'image', 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/'}, {'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\", 'type': 'text'}, {'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\", 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'type': 'text'}, {'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\", 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'type': 'text'}, {'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery', 'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'type': 'text', 'source': 'https://www.deeplearning.ai/the-batch/ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery/', 'title': 'AI Co-Scientist, An Agent That Generates Research Hypotheses, Aiding Drug Discovery'}, {'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom', 'type': 'text'}]], 'distances': [[0.0, 1.125572919845581, 1.1411538124084473, 1.4652774333953857, 1.4652774333953857, 1.4652774333953857, 1.5138983726501465, 1.5138983726501465, 1.5138983726501465, 1.5161592960357666]]}\n"
     ]
    }
   ],
   "source": [
    "#Ñ‚ÐµÑÑ‚ Ð½Ð° Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ–\n",
    "results = collection.query(\n",
    "    query_images=[numpy_images[0]]\n",
    ")\n",
    "\n",
    "print((results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad7c8606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have increased more than four-fold since 2019.Low-emissions energy has reduced Googleâ€™s total data-center emissions substantially, but some regions donâ€™t have enough of it to meet demand. Solar, wind, hydro, geothermal, and nuclear energy account for most of the energy consumed by Googleâ€™s data centers in Europe, Canada, and South America. However, these sources account for less than 5 percent in Singapore, Qatar, and Saudi Arabia.Countering the trend:Â Google is working to reduce its greenhouse gas emissions on several fronts. Its effort to purchase electricity from low-emissions sources cut its net carbon footprint by around 30 percent in 2023. It claims that its owned-and-operated data centers are 1.8 times more energy-efficient than a typical enterprise data center, and its sixth-generation tensor processing units (TPUs) are 67 percent more efficient than the prior generation. Google has asked its largest hardware partners to match 100 percent of their energy consumption with\n"
     ]
    }
   ],
   "source": [
    "docs = results.get('documents', [[]])[0]  # Ð¿ÐµÑ€ÑˆÐ¸Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ–Ð²\n",
    "\n",
    "first_non_none_doc = next((doc for doc in docs if doc is not None), None)\n",
    "print(first_non_none_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6308f6ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Ñ‚ÐµÑÑ‚ Ð½Ð° Ñ‚ÐµÐºÑÑ‚Ñ–\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m results = \u001b[43mcollection\u001b[49m.query(\n\u001b[32m      3\u001b[39m     query_texts=[\u001b[33m\"\u001b[39m\u001b[33mHow is AI growth impacting tech companies\u001b[39m\u001b[33m'\u001b[39m\u001b[33m carbon goals and data center emissions?\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      4\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m((results))\n",
      "\u001b[31mNameError\u001b[39m: name 'collection' is not defined"
     ]
    }
   ],
   "source": [
    "#Ñ‚ÐµÑÑ‚ Ð½Ð° Ñ‚ÐµÐºÑÑ‚Ñ–\n",
    "results = collection.query(\n",
    "    query_texts=[\"How is AI growth impacting tech companies' carbon goals and data center emissions?\"]\n",
    ")\n",
    "\n",
    "print((results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e456a07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom',\n",
       "   'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/',\n",
       "   'type': 'text'},\n",
       "  {'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/',\n",
       "   'type': 'text',\n",
       "   'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom'},\n",
       "  {'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom',\n",
       "   'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/',\n",
       "   'type': 'text'},\n",
       "  {'type': 'text',\n",
       "   'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\",\n",
       "   'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/'},\n",
       "  {'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\",\n",
       "   'type': 'text',\n",
       "   'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/'},\n",
       "  {'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/',\n",
       "   'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\",\n",
       "   'type': 'text'},\n",
       "  {'type': 'text',\n",
       "   'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\",\n",
       "   'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/'},\n",
       "  {'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\",\n",
       "   'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/',\n",
       "   'type': 'text'},\n",
       "  {'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\",\n",
       "   'type': 'text',\n",
       "   'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/'},\n",
       "  {'type': 'text',\n",
       "   'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom',\n",
       "   'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/'}]]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['metadatas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b11d62ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_metadata = results['metadatas'][0][0]\n",
    "first_source = first_metadata.get('source')\n",
    "first_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedeab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_imgs = collection.get(\n",
    "    where={\n",
    "        \"$and\": [\n",
    "            {\"source\": first_source},\n",
    "            {\"type\": \"image\"}\n",
    "        ]\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e8030",
   "metadata": {},
   "source": [
    "Ð²Ð¸Ð²ÐµÑÑ‚Ð¸ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a3c596e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'downloaded_images\\\\img_0.png'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_file_by_prefix(prefix, folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.startswith(prefix):\n",
    "            return os.path.join(folder, filename)\n",
    "    return None\n",
    "\n",
    "for img_id in results_imgs['ids']:\n",
    "    filepath = find_file_by_prefix(img_id, img_dir)\n",
    "    if filepath and os.path.exists(filepath):\n",
    "        img = Image.open(filepath)\n",
    "        img.show()\n",
    "    else:\n",
    "        print(f\"Ð¤Ð°Ð¹Ð» Ð´Ð»Ñ {img_id} Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾\")\n",
    "filepath        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc5745",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc0a479",
   "metadata": {},
   "source": [
    "Ð»Ð¸ÑˆÐµ Ñ‚ÐµÐºÑÑ‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6010b19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context and image:\n",
      "\n",
      "*   **Data Center Emissions:** The image demonstrates that as AI models increase in size and complexity (from \"Very small LM\" to \"Large reasoning model\"), their inference electricity consumption significantly rises, ranging from approximately 0.1 Wh to 9.0 Wh for text-generation tasks. This indicates that AI growth, particularly through the deployment of larger and more sophisticated models, will lead to increased electricity consumption by data centers. The text notes that data centers and cloud computing currently account for 1% of the world's energy-related greenhouse gas emissions.\n",
      "*   **Tech Companies' Carbon Goals:** The provided information does not directly state how AI growth impacts specific tech companies' carbon goals. However, the text suggests that AI is viewed as a powerful tool that \"stands to create huge benefits relative to the climate impact of its emissions\" and can help \"develop low-carbon energy sources and boost energy efficiency throughout society,\" implying a long-term positive potential for AI in addressing climate concerns, which could align with broader carbon reduction objectives.\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "with open(filepath, 'rb') as f:\n",
    "      image_bytes = f.read()\n",
    "query = \"How is AI growth impacting tech companies' carbon goals and data center emissions?\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    contents=[\n",
    "        types.Part(text=(\n",
    "            \"You are given a piece of text and an image. \"\n",
    "            \"Based on both, provide a clear, structured, and factual response to the following query.\\n\\n\"\n",
    "            \"Context:\\n\"\n",
    "            f\"{results['documents'][0][0]}\\n\\n\"\n",
    "            \"Query:\\n\"\n",
    "            f\"{query}\\n\"\n",
    "            \"Use only the information available in the context and image. If you cannot answer based on that, say so honestly.\"\n",
    "        )),\n",
    "        types.Part.from_bytes(\n",
    "            data=image_bytes,\n",
    "            mime_type='image/jpeg',\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0992ea6c",
   "metadata": {},
   "source": [
    "## 7. âœ… ÐŸÑ–Ð´ÑÑƒÐ¼Ð¾Ðº Ñ– Ð¾Ñ†Ñ–Ð½ÐºÐ°\n",
    "\n",
    "- Ð¯ÐºÑ–ÑÑ‚ÑŒ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÐµÐ¹\n",
    "- ÐÐ°ÑÐºÑ–Ð»ÑŒÐºÐ¸ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ– Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8114ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"chroma_langchain_db\")\n",
    "collection= client.get_collection(name=\"multimodal_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec41ced3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['text_4', 'text_22', 'text_40', 'text_16', 'text_34', 'text_52', 'text_13', 'text_31', 'text_49', 'text_20']], 'embeddings': None, 'documents': [['relieved to note that, for now, data centers and cloud computing are responsible for\\xa0 1 percent \\xa0of the worldâ€™s energy-related greenhouse gas emissions; a drop in the bucket compared to transportation, construction, or agriculture. Moreover, we believe that AI stands to create huge benefits relative to the climate impact of its emissions, and AI is one of the most powerful tools we have to develop low-carbon energy sources and boost energy efficiency throughout society. Continuing to improve the technology will help us develop lower-carbon energy sources and efficient ways to harness them.', 'relieved to note that, for now, data centers and cloud computing are responsible for\\xa0 1 percent \\xa0of the worldâ€™s energy-related greenhouse gas emissions; a drop in the bucket compared to transportation, construction, or agriculture. Moreover, we believe that AI stands to create huge benefits relative to the climate impact of its emissions, and AI is one of the most powerful tools we have to develop low-carbon energy sources and boost energy efficiency throughout society. Continuing to improve the technology will help us develop lower-carbon energy sources and efficient ways to harness them.', 'relieved to note that, for now, data centers and cloud computing are responsible for\\xa0 1 percent \\xa0of the worldâ€™s energy-related greenhouse gas emissions; a drop in the bucket compared to transportation, construction, or agriculture. Moreover, we believe that AI stands to create huge benefits relative to the climate impact of its emissions, and AI is one of the most powerful tools we have to develop low-carbon energy sources and boost energy efficiency throughout society. Continuing to improve the technology will help us develop lower-carbon energy sources and efficient ways to harness them.', 'revenues were roughly triple Googleâ€™s in 2023 and thus their AI-related greenhouse case emissions\\xa0 presumably were larger.)Why it matters:\\xa0Growing use of AI means greater consumption of energy. The tech giantsâ€™ ambitious emissions goals predate the rapid growth of generative AI, and their latest reports show that itâ€™s time to rethink them. This adds urgency to already critical efforts to develop renewable and other low-emissions energy sources.\\xa0Weâ€™re thinking:\\xa0We applaud Googleâ€™s efforts to cut its carbon emissions and its transparency in issuing annual environmental reports. Weâ€™re somewhat relieved to note that, for now, data centers and cloud computing are responsible for\\xa01 percent\\xa0of the worldâ€™s energy-related greenhouse gas emissions; a drop in the bucket compared to transportation, construction, or agriculture. Moreover, we believe that AI stands to create huge benefits relative to the climate impact of its emissions, and AI is one of the most powerful tools we have to develop', 'revenues were roughly triple Googleâ€™s in 2023 and thus their AI-related greenhouse case emissions\\xa0 presumably were larger.)Why it matters:\\xa0Growing use of AI means greater consumption of energy. The tech giantsâ€™ ambitious emissions goals predate the rapid growth of generative AI, and their latest reports show that itâ€™s time to rethink them. This adds urgency to already critical efforts to develop renewable and other low-emissions energy sources.\\xa0Weâ€™re thinking:\\xa0We applaud Googleâ€™s efforts to cut its carbon emissions and its transparency in issuing annual environmental reports. Weâ€™re somewhat relieved to note that, for now, data centers and cloud computing are responsible for\\xa01 percent\\xa0of the worldâ€™s energy-related greenhouse gas emissions; a drop in the bucket compared to transportation, construction, or agriculture. Moreover, we believe that AI stands to create huge benefits relative to the climate impact of its emissions, and AI is one of the most powerful tools we have to develop', 'revenues were roughly triple Googleâ€™s in 2023 and thus their AI-related greenhouse case emissions\\xa0 presumably were larger.)Why it matters:\\xa0Growing use of AI means greater consumption of energy. The tech giantsâ€™ ambitious emissions goals predate the rapid growth of generative AI, and their latest reports show that itâ€™s time to rethink them. This adds urgency to already critical efforts to develop renewable and other low-emissions energy sources.\\xa0Weâ€™re thinking:\\xa0We applaud Googleâ€™s efforts to cut its carbon emissions and its transparency in issuing annual environmental reports. Weâ€™re somewhat relieved to note that, for now, data centers and cloud computing are responsible for\\xa01 percent\\xa0of the worldâ€™s energy-related greenhouse gas emissions; a drop in the bucket compared to transportation, construction, or agriculture. Moreover, we believe that AI stands to create huge benefits relative to the climate impact of its emissions, and AI is one of the most powerful tools we have to develop', 'attributes the rise to its efforts to satisfy rising demand for AI.\\xa0How it works:\\xa0Googleâ€™s carbon emissions increased 16.7 percent from 2021 to 2022 and another 13.5 percent from 2022 to 2023 for a total 48 percent rise over those periods. â€œAs we further integrate AI into our products, reducing emissions may be challenging due to increasing energy demands from the greater intensity of AI compute, and the emissions associated with the expected increases in our technical infrastructure investment,â€ the report states.Three-quarters of total emissions, or 10.8 million tons, are associated with purchases that include the data-center hardware and construction. These emissions increased 23 percent from 2019 to 2023 and 8 percent year-over-year.Powering, heating, and cooling data centers and other facilities accounted for around a quarter of Googleâ€™s 2023 emissions. Emissions from these activities have increased more than four-fold since 2019.Low-emissions energy has reduced Googleâ€™s total', 'attributes the rise to its efforts to satisfy rising demand for AI.\\xa0How it works:\\xa0Googleâ€™s carbon emissions increased 16.7 percent from 2021 to 2022 and another 13.5 percent from 2022 to 2023 for a total 48 percent rise over those periods. â€œAs we further integrate AI into our products, reducing emissions may be challenging due to increasing energy demands from the greater intensity of AI compute, and the emissions associated with the expected increases in our technical infrastructure investment,â€ the report states.Three-quarters of total emissions, or 10.8 million tons, are associated with purchases that include the data-center hardware and construction. These emissions increased 23 percent from 2019 to 2023 and 8 percent year-over-year.Powering, heating, and cooling data centers and other facilities accounted for around a quarter of Googleâ€™s 2023 emissions. Emissions from these activities have increased more than four-fold since 2019.Low-emissions energy has reduced Googleâ€™s total', 'attributes the rise to its efforts to satisfy rising demand for AI.\\xa0How it works:\\xa0Googleâ€™s carbon emissions increased 16.7 percent from 2021 to 2022 and another 13.5 percent from 2022 to 2023 for a total 48 percent rise over those periods. â€œAs we further integrate AI into our products, reducing emissions may be challenging due to increasing energy demands from the greater intensity of AI compute, and the emissions associated with the expected increases in our technical infrastructure investment,â€ the report states.Three-quarters of total emissions, or 10.8 million tons, are associated with purchases that include the data-center hardware and construction. These emissions increased 23 percent from 2019 to 2023 and 8 percent year-over-year.Powering, heating, and cooling data centers and other facilities accounted for around a quarter of Googleâ€™s 2023 emissions. Emissions from these activities have increased more than four-fold since 2019.Low-emissions energy has reduced Googleâ€™s total', 'its net carbon footprint by around 30 percent in 2023. It claims that its owned-and-operated data centers are 1.8 times more energy-efficient than a typical enterprise data center, and its sixth-generation tensor processing units (TPUs) are 67 percent more efficient than the prior generation. Google has asked its largest hardware partners to match 100 percent of their energy consumption with renewable energy 2029. The company is pursuing several AI-based initiatives to mitigate climate change from weather prediction to fuel-efficient vehicle routing. It says that AI has the potential to mitigate 5 to 10 percent of global greenhouse gas emissions by 2030. Behind the news: \\xa0In 2020, after five years of successfully\\xa0 reducing \\xa0its carbon footprint, Google set an ambitious target to reach net-zero greenhouse gas emissions by 2030. But its total emissions since then have risen each year. Googleâ€™s experience mirrors that of Amazon and Microsoft, which aim to reach net-zero carbon emissions']], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[{'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom', 'type': 'text'}, {'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom', 'type': 'text'}, {'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom', 'type': 'text'}, {'type': 'text', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\", 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/'}, {'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'type': 'text', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\"}, {'type': 'text', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\", 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/'}, {'type': 'text', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\", 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/'}, {'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\", 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/', 'type': 'text'}, {'type': 'text', 'title': \"AI and Data Center Boom Challenges Big Tech's Emissions Targets\", 'source': 'https://www.deeplearning.ai/the-batch/ai-and-data-center-boom-challenges-big-techs-emissions-targets/'}, {'type': 'text', 'title': 'The International Energy Agency Examines The Energy Costs and Potential Savings of the AI Boom', 'source': 'https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/'}]], 'distances': [[0.29250115156173706, 0.29250115156173706, 0.29250115156173706, 0.3493429720401764, 0.3493429720401764, 0.3493429720401764, 0.37661588191986084, 0.37661588191986084, 0.37661588191986084, 0.424465149641037]]}\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"How is AI growth impacting tech companies' carbon goals and data center emissions?\"]\n",
    ")\n",
    "\n",
    "print((results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "186d34db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, Dict\n",
    "from utils import file_by_prefix\n",
    "class AbstractContextFetcher(ABC):\n",
    "    def __init__(self, collection: Any):\n",
    "        self.collection = collection\n",
    "\n",
    "    @abstractmethod\n",
    "    def build_context(self, query_result: Dict) -> Dict:\n",
    "        \"\"\"ÐŸÐ¾Ð²ÐµÑ€Ñ‚Ð°Ñ” Ð¿Ð¾Ð²'ÑÐ·Ð°Ð½Ð¸Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚\"\"\"\n",
    "        pass\n",
    "\n",
    "class TextContextFetcher(AbstractContextFetcher):\n",
    "    \"\"\"Ð¿Ð¾Ð²â€™ÑÐ·Ð°Ð½Ð½Ñ–(((Ð² Ð¾Ð´Ð½Ð¸Ð½Ñ–))) Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ(((Ð² Ð¾Ð´Ð½Ð¸Ð½Ñ–))) Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ð¸Ñ‚Ñƒ\"\"\"\n",
    "    def build_context(self, query_result: Dict) -> Dict:\n",
    "        first_metadata = query_result['metadatas'][0][0]\n",
    "        results_imgs = self.collection.get(\n",
    "            where={\n",
    "                \"$and\": [\n",
    "                    {\"source\": first_metadata.get('source')},\n",
    "                    {\"type\": \"image\"}\n",
    "                    ]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        filepath = file_by_prefix(results_imgs['ids'][0]) # Ð½Ð° Ð¿ÐµÑ€ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ñƒ Ð· Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ñ–ÑÑ‚ÑŽ Ð±Ñ–Ð»ÑŒÑˆÐ¾Ñ— ÐºÑ–Ð»ÑŒÐºÐ¾ÑÑ‚Ñ– Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ\n",
    "        text = query_result['documents'][0][0] if query_result['documents'][0] else None\n",
    "   \n",
    "        return {\"image_path\": filepath, \"text\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b95fee41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_path': 'downloaded_images\\\\img_0.png',\n",
       " 'text': 'relieved to note that, for now, data centers and cloud computing are responsible for\\xa0 1 percent \\xa0of the worldâ€™s energy-related greenhouse gas emissions; a drop in the bucket compared to transportation, construction, or agriculture. Moreover, we believe that AI stands to create huge benefits relative to the climate impact of its emissions, and AI is one of the most powerful tools we have to develop low-carbon energy sources and boost energy efficiency throughout society. Continuing to improve the technology will help us develop lower-carbon energy sources and efficient ways to harness them.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = TextContextFetcher(collection)\n",
    "t.build_context(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
